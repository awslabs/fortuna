{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c34e2bf2",
   "metadata": {},
   "source": [
    "# Two-moons Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb87d1d",
   "metadata": {},
   "source": [
    "In this notebook we show how to use Fortuna to obtain calibrated uncertainty estimates of predictions in an MNIST classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd50eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, './../src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffc357d",
   "metadata": {},
   "source": [
    "### Download Two-Moons data from scikit-learn\n",
    "Let us first download two-moons data from [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db38dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "train_data = make_moons(n_samples=10000, noise=0.07, random_state=0)\n",
    "val_data = make_moons(n_samples=1000, noise=0.07, random_state=1)\n",
    "test_data = make_moons(n_samples=1000, noise=0.07, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d84bad3",
   "metadata": {},
   "source": [
    "### Convert data to a compatible data loader\n",
    "Fortuna helps you converting data and data loaders into a data loader that Fortuna can digest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fortuna.data import DataLoader\n",
    "train_data_loader = DataLoader.from_array_data(train_data, batch_size=128, shuffle=True, prefetch=True)\n",
    "val_data_loader = DataLoader.from_array_data(val_data, batch_size=128, prefetch=True)\n",
    "test_data_loader = DataLoader.from_array_data(test_data, batch_size=128, prefetch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0725da5",
   "metadata": {},
   "source": [
    "### Build a probabilistic classifier\n",
    "Let us build a probabilistic classifier. This is an interface object containing several attributes that you can configure, i.e. `model`, `prior`, `posterior_approximator`, `output_calibrator`. In this example, we use an MLP model, an Automatic Differentiation Variational Inference posterior approximator, and the default temperature scaling output calibrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41018b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fortuna.prob_model import ProbClassifier\n",
    "from fortuna.model import MLP\n",
    "from fortuna.prob_model.posterior import ADVIPosteriorApproximator\n",
    "import flax.linen as nn\n",
    "output_dim = 2\n",
    "prob_model = ProbClassifier(\n",
    "    model=MLP(output_dim=output_dim, activations=(nn.tanh, nn.tanh)),\n",
    "    posterior_approximator=ADVIPosteriorApproximator()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e8a075",
   "metadata": {},
   "source": [
    "### Train the probabilistic model: posterior fitting and calibration\n",
    "We can now train the probabilistic model. This includes fitting the posterior distribution and calibrating the probabilistic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a9201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fortuna.prob_model.fit_config import FitConfig, FitMonitor, FitOptimizer\n",
    "from fortuna.metric.classification import accuracy\n",
    "import optax\n",
    "status = prob_model.train(\n",
    "    train_data_loader=train_data_loader,\n",
    "    val_data_loader=val_data_loader,\n",
    "    calib_data_loader=val_data_loader,\n",
    "    fit_config=FitConfig(monitor=FitMonitor(metrics=(accuracy,)), optimizer=FitOptimizer(method=optax.adam(1e-1)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26da085",
   "metadata": {},
   "source": [
    "### Estimate predictive statistics\n",
    "We can now compute some predictive statistics by invoking the `predictive` attribute of the probabilistic classifier, and the method of interest. Most predictive statistics, e.g. mean or mode, require a loader of input data points. You can easily get this from the data loader calling its method `to_inputs_loader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663546ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_log_probs = prob_model.predictive.log_prob(data_loader=test_data_loader)\n",
    "test_inputs_loader = test_data_loader.to_inputs_loader()\n",
    "test_means = prob_model.predictive.mean(inputs_loader=test_inputs_loader)\n",
    "test_modes = prob_model.predictive.mode(inputs_loader=test_inputs_loader, means=test_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from fortuna.data import InputsLoader\n",
    "import numpy as np\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "size = 150\n",
    "xx = np.linspace(-4, 4, size)\n",
    "yy = np.linspace(-4, 4, size)\n",
    "grid = np.array([[_xx, _yy] for _xx in xx for _yy in yy])\n",
    "grid_loader = InputsLoader.from_array_inputs(grid)\n",
    "grid_entropies = prob_model.predictive.entropy(grid_loader).reshape(size, size)\n",
    "grid = grid.reshape(size, size, 2)\n",
    "plt.title(\"Predictions and entropy\", fontsize=12)\n",
    "im = plt.pcolor(grid[:, :, 0], grid[:, :, 1], grid_entropies)\n",
    "plt.scatter(test_data[0][:, 0], test_data[0][:, 1], s=1, c=[\"C0\" if i == 1 else \"C1\" for i in test_modes])\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdfe0b5",
   "metadata": {},
   "source": [
    "### Compute metrics\n",
    "In classification, the predictive mode is a prediction for labels, while the predictive mean is a prediction for the probability of each label. As such, we can use these to compute several metrics, e.g. the accuracy, the Brier score, the expected calibration error (ECE), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad646417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fortuna.metric.classification import accuracy, expected_calibration_error, brier_score\n",
    "test_targets = test_data_loader.to_array_targets()\n",
    "acc = accuracy(preds=test_modes, targets=test_targets)\n",
    "brier = brier_score(probs=test_means, targets=test_targets)\n",
    "ece = expected_calibration_error(preds=test_modes, probs=test_means, targets=test_targets, plot=True, figsize=(10, 2))\n",
    "print(f\"Test accuracy: {acc}\")\n",
    "print(f\"Brier score: {brier}\")\n",
    "print(f\"ECE: {ece}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd94df",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### What if we had had model outputs to start from?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150dd8df",
   "metadata": {},
   "source": [
    "If you have already trained a model and obtained model outputs, you can still use Fortuna to calibrate them, and estimate uncertainty. For educational purposes only, let us take the logarithm of the predictive mean estimated above as model outputs, and pretend these were generated with some other framework. Furthermore, we store arrays of validation and test target variables, and assume these were also given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0df94f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "val_outputs = np.log(1e-6 + prob_model.predictive.mean(inputs_loader=val_data_loader.to_inputs_loader()))\n",
    "test_outputs = np.log(1e-6 + test_means)\n",
    "\n",
    "val_targets = val_data_loader.to_array_targets()\n",
    "test_targets = test_data_loader.to_array_targets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb6dd8d",
   "metadata": {},
   "source": [
    "We now invoke a calibration classifier, with default temperature scaling output calibrator, and calibrate the model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec732e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fortuna.calib_model.classification import CalibClassifier\n",
    "calib_model = CalibClassifier()\n",
    "calib_status = calib_model.calibrate(outputs=val_outputs, targets=val_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae705150",
   "metadata": {},
   "source": [
    "Similarly as above, we can now compute predictive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9af781",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_log_probs = calib_model.predictive.log_prob(outputs=test_outputs, targets=test_targets)\n",
    "test_means = calib_model.predictive.mean(outputs=test_outputs)\n",
    "test_modes = calib_model.predictive.mode(outputs=test_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc91687",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then one can compute metrics, exactly as done above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fortunaenv",
   "language": "python",
   "name": "fortunaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}