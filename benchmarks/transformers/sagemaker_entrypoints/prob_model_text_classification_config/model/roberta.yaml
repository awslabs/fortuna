name: "roberta"
hparams:
  model_name_or_path: "roberta-base"
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  learning_rate: 5e-5
  num_warmup_steps: 500
  prior_log_var: 20.
  weight_decay: 0.0
